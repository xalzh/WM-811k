{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-06-21T14:33:14.354801Z",
     "end_time": "2023-06-21T14:33:17.396892Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the oversampled_train_data and preprocessed_test_data from pickle files\n",
    "with open('dataset/preprocessed_train_data.pkl', 'rb') as f:\n",
    "    loaded_oversampled_train_data = pickle.load(f)\n",
    "\n",
    "with open('dataset/preprocessed_test_data.pkl', 'rb') as f:\n",
    "    loaded_preprocessed_test_data = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-21T14:33:17.388893Z",
     "end_time": "2023-06-21T14:33:18.088892Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class WaferMapDataset(Dataset):\n",
    "    def __init__(self, data_dict):\n",
    "        self.data_dict = data_dict\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        self.label_map = {'Center': 0, 'Donut': 1, 'Edge-Loc': 2, 'Edge-Ring': 3, 'Loc': 4,\n",
    "                          'Random': 5, 'Scratch': 6, 'Near-full': 7, 'none': 8}\n",
    "\n",
    "        for label, images in self.data_dict.items():\n",
    "            for image in images:\n",
    "                self.samples.append(image)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert the image to a PyTorch tensor and add a channel dimension\n",
    "        image_tensor = torch.tensor(self.samples[idx], dtype=torch.float32).unsqueeze(0)\n",
    "        label = self.label_map[self.labels[idx]]\n",
    "        label_tensor  = torch.tensor(label, dtype=torch.long).squeeze()\n",
    "        return image_tensor, label_tensor\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-21T14:33:18.088892Z",
     "end_time": "2023-06-21T14:33:18.104892Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the custom datasets\n",
    "train_dataset = WaferMapDataset(loaded_oversampled_train_data)\n",
    "test_dataset = WaferMapDataset(loaded_preprocessed_test_data)\n",
    "\n",
    "print(loaded_preprocessed_test_data.keys())\n",
    "# Create the DataLoader instances\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-21T14:33:18.105893Z",
     "end_time": "2023-06-21T14:33:18.151892Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = model.compute_loss(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    epoch_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    return epoch_loss, accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-21T14:33:18.123892Z",
     "end_time": "2023-06-21T14:33:18.168894Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = model.compute_loss(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    epoch_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    return epoch_loss, accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-21T14:33:18.138893Z",
     "end_time": "2023-06-21T14:33:18.168894Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Import Models\n",
    "from models.CNN import cnn\n",
    "from models.ResNet18 import CustomResNet18\n",
    "from models.ResNet152 import CustomResNet152\n",
    "from models.ResNet101 import CustomResNet101\n",
    "from models.ResNet50 import CustomResNet50\n",
    "from models.DCNN import OptResDCNN\n",
    "from models.DenseNet121 import CustomDenseNet121\n",
    "from models.MobileNet import CustomMobileNet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-21T14:33:18.154893Z",
     "end_time": "2023-06-21T14:33:18.406404Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Instantiate the model and move it to the appropriate device\n",
    "models = [cnn(num_classes=9, dropout_rate=0).to(device),\n",
    "          CustomResNet18(num_classes=9, dropout_rate=0).to(device),\n",
    "          CustomResNet50(num_classes=9, dropout_rate=0).to(device),\n",
    "          CustomResNet152(num_classes=9, dropout_rate=0).to(device),\n",
    "          CustomResNet101(num_classes=9, dropout_rate=0).to(device),\n",
    "          OptResDCNN(num_classes=9, dropout_rate=0).to(device),\n",
    "          CustomDenseNet121(num_classes=9, dropout_rate=0).to(device),\n",
    "          CustomMobileNet(num_classes=9, dropout_rate=0).to(device)]\n",
    "\n",
    "#models = [CustomMobileNet(num_classes=9, dropout_rate=0).to(device)]\n",
    "\n",
    "for model in models:\n",
    "    model_name = type(model).__name__\n",
    "    print(model_name)\n",
    "\n",
    "    # Create an optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    time_per_epoch = []\n",
    "    loss_values = [[],[]]\n",
    "    acc = [[],[]]\n",
    "    num_epochs = 50\n",
    "    test = 0.4\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss, train_accuracy = train(model, train_dataloader, optimizer, device)\n",
    "        test_loss, test_accuracy = evaluate(model, test_dataloader, device)\n",
    "        end_time = time.time()\n",
    "\n",
    "        loss_values[0].append(train_loss)\n",
    "        acc[0].append(train_accuracy)\n",
    "        loss_values[1].append(test_loss)\n",
    "        acc[1].append(test_accuracy)\n",
    "        epoch_time = end_time - start_time\n",
    "        time_per_epoch.append(epoch_time)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "    with open('results/'+model_name+'.pkl', 'wb') as file:\n",
    "        pickle.dump({\"time_per_epoch\": time_per_epoch, \"loss_values\": loss_values, \"accuracy\": acc}, file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-21T14:36:06.363075Z",
     "end_time": "2023-06-21T14:44:28.016298Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T20:40:17.049312Z",
     "end_time": "2023-04-26T20:40:17.079311Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
